# -*- coding: utf-8 -*-
"""Malcolm_Clottey_Assignment_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EtDjV6fIpCFAqSHCamHmnZJXyYeqPbqf
"""

!pip install tensorflow --upgrade
!pip install keras --upgrade

"""IMPORTING LIBRARIES"""

#importing modules
import pandas as pd
import os
import sklearn
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report
import numpy as np, pandas as pd
import matplotlib.pyplot as plt
from sklearn import tree, metrics
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
from google.colab import drive
from sklearn.metrics import accuracy_score
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
from keras.models import Model
from keras.layers import Input, Dense
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
import joblib

drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Telco_Customer_Churn_Dataset.csv')
df.info()
df.head()

"""USING FEATURE IMPORTANCE FOR FEATURE EXTRACTION"""

numeric_cols = ['SeniorCitizen', 'tenure', 'MonthlyCharges']
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())

# Replace NaN values in object columns with 'Unknown'
object_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',
               'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',
               'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',
               'PaperlessBilling', 'PaymentMethod', 'TotalCharges', 'Churn']
df[object_cols] = df[object_cols].fillna('Unknown')

# Ensure 'TotalCharges' column is of numeric type after replacing NaN values
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df['TotalCharges'] = df['TotalCharges'].fillna(0)

df

# Separate features and target variable
X = df.drop(['customerID', 'Churn'], axis=1)
y = df['Churn']

from sklearn.compose import ColumnTransformer
# Identify categorical columns
categorical_cols = X.select_dtypes(include=['object']).columns

# Apply one-hot encoding to categorical columns
preprocessor = ColumnTransformer(
    transformers=[('cat', OneHotEncoder(), categorical_cols)],
    remainder='passthrough'
)

X = preprocessor.fit_transform(X)

# Initialize and train the RandomForestClassifier
clf = RandomForestClassifier(random_state=42)
clf.fit(X, y)

# Get feature importances
feature_importances = clf.feature_importances_

feature_importances = clf.feature_importances_

# Create a DataFrame to display feature names and their importance scores
feature_importance_df = pd.DataFrame({'Feature': preprocessor.get_feature_names_out(), 'Importance': feature_importances})

# Sort the DataFrame by importance in descending order
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Print feature importances
print(feature_importance_df)

selected_columns = ['Churn','SeniorCitizen','gender', 'tenure','InternetService','OnlineSecurity','StreamingTV','StreamingMovies','Contract','PaymentMethod','PaperlessBilling','MonthlyCharges','TotalCharges']

"""DATA PREPROCESSING"""

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Telco_Customer_Churn_Dataset.csv', usecols=selected_columns)
df.info()

df.head()

"""FEATURE AUGMENTATION"""

#Combine 'StreamingTV' and 'StreamingMovies' into a new feature 'Streaming'
df['Streaming'] = df['StreamingTV'].apply(lambda x: 1 if x == 'Yes' else 0) + df['StreamingMovies'].apply(lambda x: 1 if x == 'Yes' else 0)

# Drop the original 'StreamingTV' and 'StreamingMovies' columns
df.drop(['StreamingTV', 'StreamingMovies'], axis=1, inplace=True)

# Convert 'TotalCharges' column to numeric
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# Fill missing values with the mean of the column
mean_total_charges = df['TotalCharges'].mean()
df['TotalCharges'] = df['TotalCharges'].fillna(mean_total_charges)

df.info()

df.head()

#Encoding Churn column
df = pd.get_dummies(df, columns=['Churn'], drop_first=True)
df
df.info()

"""SCALING NUMERICAL DATA"""

from sklearn.preprocessing import StandardScaler

# Select the numerical features
numerical_features = ['SeniorCitizen', 'tenure','Streaming', 'MonthlyCharges', 'TotalCharges']

# Initialize the StandardScaler
scaler = StandardScaler()

# Scale the numerical features
df[numerical_features] = scaler.fit_transform(df[numerical_features])

"""ONE-HOT ENCODING CATEGORICAL DATA"""

from sklearn.preprocessing import OneHotEncoder

# Select categorical columns for one-hot encoding
categorical_cols = ['gender','PaymentMethod','InternetService', 'OnlineSecurity', 'Contract', 'PaperlessBilling']

# Initialize the OneHotEncoder
encoder = OneHotEncoder(drop='first', sparse=False)

# Apply one-hot encoding to the selected categorical columns
encoded_features = encoder.fit_transform(df[categorical_cols])

# Create a DataFrame with the encoded features
encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_cols))

# Concatenate the encoded features with the original DataFrame
df = pd.concat([df, encoded_df], axis=1)

# Drop the original categorical columns
df.drop(categorical_cols, axis=1, inplace=True)

df.info()
df.head()

# Separate features and target variable
X = df.drop(['Churn_Yes'], axis=1)
y = df['Churn_Yes']

X

"""TRAINING MLP MODEL"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# Initialize individual MLP models
mlp = MLPClassifier(max_iter=1000, random_state=42)

# Define parameter grid for grid search
param_grid = {
    'hidden_layer_sizes': [(100, 50), (50, 25), (75, 30)],
    'alpha': [0.0001, 0.001, 0.01],
}

# Create a GridSearchCV object
grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)

# Perform grid search on the training data
grid_search.fit(X_train, y_train)

# Get the best model from the grid search
best_mlp = grid_search.best_estimator_

# Print the best parameters found by grid search
print("Best Parameters:", grid_search.best_params_)

# Make predictions using the best model
y_pred_best = best_mlp.predict(X_test)

# Calculate accuracy
accuracy_best = accuracy_score(y_test, y_pred_best)
print(f'Best Model Accuracy: {accuracy_best:.2f}')

X.info()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# Initialize individual MLP models
mlp1 = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)
mlp2 = MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=1000, random_state=42)
mlp3 = MLPClassifier(hidden_layer_sizes=(75, 30), max_iter=1000, random_state=42)

# Create a VotingClassifier ensemble
ensemble_clf = VotingClassifier(estimators=[
    ('mlp1', mlp1),
    ('mlp2', mlp2),
    ('mlp3', mlp3)
], voting='soft')

# Train the ensemble model
ensemble_clf.fit(X_train, y_train)

# Make predictions using the ensemble model
y_pred_ensemble = ensemble_clf.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred_ensemble)
print(f'Accuracy: {accuracy:.2f}')

# Calculate AUC score
auc_score = roc_auc_score(y_test, y_pred_ensemble)
print(f'AUC Score: {auc_score:.2f}')

# Evaluate the ensemble model
accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)
print(f'Ensemble Model Accuracy: {accuracy_ensemble:.2f}')

"""TRAINING MLP MODEL USING THE KERAS FUNCTIONAL API"""

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# Standardize features by removing the mean and scaling to unit variance
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define the input layer
input_layer = Input(shape=(X_train_scaled.shape[1],))

# Define hidden layers
hidden1 = Dense(units=300, activation='tanh')(input_layer)
hidden2 = Dense(units=200, activation='tanh')(hidden1)
hidden3 = Dense(units=150, activation='tanh')(hidden2)
hidden4 = Dense(units=100, activation='tanh')(hidden3)
hidden5 = Dense(units=75, activation='tanh')(hidden4)
hidden6 = Dense(units=50, activation='tanh')(hidden5)
hidden7 = Dense(units=25, activation='tanh')(hidden6)

# Define output layer
output_layer = Dense(units=1, activation='sigmoid')(hidden7)

# Create the model
model = Model(inputs=input_layer, outputs=output_layer)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train_scaled, y_train, epochs=10, batch_size=100, validation_split=0.1)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test_scaled, y_test)
print(f'Loss: {loss:.2f}')
print(f'Accuracy: {accuracy:.2f}')

# Predict probabilities for the positive class
y_pred_proba = model.predict(X_test_scaled)

# Calculate AUC score
auc_score = roc_auc_score(y_test, y_pred_proba)
print(f'AUC Score: {auc_score:.2f}')

"""Hyperparameter Tuning for Multi-Layer Perceptron (MLP) Classifier"""

# Standardize numerical features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Define the KerasClassifier-compatible function
def create_model(hidden_layers=(300, 200, 150, 100, 75, 50, 25), learning_rate=0.0001):
    model = MLPClassifier(hidden_layer_sizes=hidden_layers, learning_rate_init=learning_rate, max_iter=1000)
    return model

# Define hyperparameters grid
param_grid = {
    'hidden_layer_sizes': [(300, 200, 150, 100, 75, 50, 25), (200, 100, 50), (100,)],
    'learning_rate_init': [0.0001, 0.001, 0.01],
}

# Create GridSearchCV object
grid_search = GridSearchCV(estimator=create_model(), param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)

# Perform grid search on the entire dataset (X_scaled, y)
grid_search.fit(X_scaled, y)

# Get the best model from the grid search
best_model = grid_search.best_estimator_

# Print the best parameters found by grid search
print("Best Parameters:", grid_search.best_params_)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=42)

# Evaluate the best model on the test set
accuracy_best = best_model.score(X_test, y_test)
print(f'Best Model Accuracy: {accuracy_best:.2f}')

# Evaluate the best model on the test set
y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # Predict probabilities for positive class
auc_score = roc_auc_score(y_test, y_pred_proba)
print(f'AUC Score: {auc_score:.2f}')

from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import roc_auc_score, accuracy_score
import numpy as np
import pandas as pd

# Split the data into training, validation, and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.01, random_state=42)  # 0.25 x 0.8 = 0.2

# Standardize numerical features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Define the KerasClassifier-compatible function
def create_model(hidden_layers=(150, 100, 75, 50, 25),
                activation='relu',
                solver='adam',
                alpha=0.0001,
                learning_rate='constant',
                learning_rate_init=0.0001,
                batch_size=32):
    model = MLPClassifier(hidden_layer_sizes=hidden_layers,
                          activation=activation,
                          solver=solver,
                          alpha=alpha,
                          learning_rate=learning_rate,
                          learning_rate_init=learning_rate_init,
                          batch_size=batch_size,
                          max_iter=1000)
    return model

# Define hyperparameters grid
param_grid = {
    'hidden_layer_sizes': [(100, 75, 50, 25), (200, 100, 50), (100,)],
    'activation': ['tanh'],
    'solver': ['adam', 'sgd', 'lbfgs'],
    'alpha': [0.0001, 0.001, 0.01, 0.1],
    'learning_rate_init': [0.0001, 0.001, 0.01],
    'learning_rate': ['constant', 'adaptive'],
    'batch_size': [32, 64, 128]
}

# Create GridSearchCV object
grid_search = GridSearchCV(estimator=create_model(), param_grid=param_grid, cv=3, scoring='roc_auc', n_jobs=-1)

# Perform grid search on the entire dataset (X_train_scaled, y_train)
grid_search.fit(X_train_scaled, y_train)

# Get the best model from the grid search
best_model = grid_search.best_estimator_

# Print the best parameters found by grid search
print("Best Parameters:", grid_search.best_params_)

# Evaluate the best model on the test set
y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]  # Predict probabilities for positive class
auc_score = roc_auc_score(y_test, y_pred_proba)
print(f'AUC Score on Test Set: {auc_score:.2f}')

# Implement Cross-validation to calculate training and validation loss, accuracy
cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='roc_auc')
print(f'Cross-validation AUC scores: {cv_scores}')
print(f'Mean AUC from cross-validation: {np.mean(cv_scores):.2f} (+/- {np.std(cv_scores):.2f})')

# Train the best model on the entire training set to get training/validation metrics
best_model.fit(X_train_scaled, y_train)
train_loss = best_model.loss_
train_accuracy = accuracy_score(y_train, best_model.predict(X_train_scaled))
val_loss = best_model.score(X_val_scaled, y_val)
val_accuracy = accuracy_score(y_val, best_model.predict(X_val_scaled))

print(f"Training Loss: {train_loss:.2f}, Validation Loss: {val_loss:.2f}")
print(f"Training Accuracy: {train_accuracy:.2f}, Validation Accuracy: {val_accuracy:.2f}")

"""Training and Validation Loss Comparison Over Epochs"""

import matplotlib.pyplot as plt
history = best_model.fit(X_train_scaled, y_train)

train_loss = history.loss_curve_
val_loss = best_model.score(X_val_scaled, y_val)

# Plot training and validation loss
plt.figure(figsize=(10, 6))
plt.plot(train_loss, label='Training Loss')
plt.axhline(y=val_loss, color='r', linestyle='--', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

import joblib
import pickle

# Save the OneHotEncoder object
with open('/content/drive/My Drive/Colab Notebooks/one_hot_encoder.pkl', 'wb') as file:
    joblib.dump(encoder, file)

# saving the scaler object using joblib for later use in ensemble models
joblib.dump(scaler, '/content/drive/My Drive/Colab Notebooks/scaler.pkl')

# Save the model
model.save('/content/drive/My Drive/Colab Notebooks/best_model.h5')